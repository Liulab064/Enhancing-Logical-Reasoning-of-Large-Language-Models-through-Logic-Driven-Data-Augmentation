# Logical-and-abstract-reasoning

## Datasets & Benchmarks
<h4 id="2.1.1">Datasets & Benchmarks</h4>

<table>
  <tr>
      <th colspan="2" align="center">Inference Type</th>
      <th align="center">Dataset</th>
      <th align="center">Size</th>
      <th align="center">Task</th>
      <th align="center">Link</th>
      <th align="center">Remark</th>
  </tr >
  
  <tr>
      <th rowspan="3" colspan="2" align="center" valign="middle">Logical Reasoning on Reading Comprehension</th>
      <td align="center">ReClor</td>
      <td align="center">-</td>
      <td align="center">Reading Comprehension</td>
      <td align="center"> <a href="https://openreview.net/pdf?id=HJgJtT4tvB">paper</a> <br /> <a href="https://whyu.me/reclor/">project</a>  </td>
      <td align="center">Logical reasoning reading comprehension</td>
  </tr>
  <tr>
      <td align="center">LogiQA</td>
      <td align="center">-</td>
      <td align="center">Reading Comprehension</td>
      <td align="center"> <a href="https://www.ijcai.org/proceedings/2020/0501.pdf">paper</a> <br /> <a href="https://github.com/lgw863/LogiQA-dataset">project</a>  </td>
      <td align="center">Logoical reasoning reading comprehension</td>
  </tr>
  <tr>
      <td align="center">LogiQA V2</td>
      <td align="center">-</td>
      <td align="center">Reading Comprehension</td>
      <td align="center"> <a href="https://github.com/openai/evals/pull/470">project</a>  </td>
      <td align="center">Logoical reasoning reading comprehension</td>
  </tr>
</table>

