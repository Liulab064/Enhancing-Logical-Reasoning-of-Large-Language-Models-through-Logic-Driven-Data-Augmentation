
model_name: "llama"
model_weights: "/data/shared/llama/7B/"
task: "open_qa"
max_new_tokens: 128
model_config_args:
  fsdp_transformer_layer_cls_to_wrap: "LLaMADecoderLayer"