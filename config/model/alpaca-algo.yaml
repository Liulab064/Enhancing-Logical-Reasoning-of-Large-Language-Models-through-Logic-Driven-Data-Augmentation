
model_name: "alpaca"
model_weights: "chainyo/alpaca-lora-7b"
task: "algo"
max_new_tokens: 128
model_config_args:
  fsdp_transformer_layer_cls_to_wrap: "LLaMADecoderLayer"